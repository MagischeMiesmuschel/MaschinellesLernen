{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest-Neighbor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [  1 ,   7 ,  1 ,   1 ,  \"spo\" ],\n",
    "    [  2 ,  13 ,  0 ,   1 ,  \"spo\" ],\n",
    "    [  3 ,   8 ,  2 ,   1 ,  \"spo\" ],\n",
    "    [  4 ,   7 ,  2 ,   3 ,  \"spo\" ],\n",
    "    [  5 ,   2 ,  1 ,   0 ,  \"sci\" ],\n",
    "    [  6 ,   1 ,  0 ,   1 ,  \"sci\" ],\n",
    "    [  7 ,   2 ,  2 ,   1 ,  \"sci\" ],\n",
    "    [  8 ,  12 ,  8 ,  11 ,  \"his\" ],\n",
    "    [  9 ,   7 ,  3 ,   5 ,  \"his\" ],\n",
    "    [ 10 ,   6 ,  5 ,   8 ,  \"his\" ]],\n",
    "    columns=[  \"DocId\" ,  \"$X_p$\" ,  \"$X_l$\" ,  \"$X_d$\" ,  \"$Y$\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a collection of text documents that each have been classified according to their content into the three classes\n",
    "*sports*, *scientific*, and *historical*.\n",
    "\n",
    "Furthermore, three integer features $(X_p, X_l, X_d)$ have been obtained for each document,\n",
    "by detecting named entities and tagging each entity as *person*, *location*, or *date*,\n",
    "and counting the number of times each kind of entity occurs.\n",
    "\n",
    "For each training document, you know $X_p, X_l, X_d$ and the class label $Y = \\{\\text{spo}, \\text{sci}, \\text{his}\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocId</th>\n",
       "      <th>$X_p$</th>\n",
       "      <th>$X_l$</th>\n",
       "      <th>$X_d$</th>\n",
       "      <th>$Y$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>spo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>spo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocId  $X_p$  $X_l$  $X_d$  $Y$\n",
       "0      1      7      1      1  spo\n",
       "1      2     13      0      1  spo\n",
       "2      3      8      2      1  spo\n",
       "3      4      7      2      3  spo\n",
       "4      5      2      1      0  sci\n",
       "5      6      1      0      1  sci\n",
       "6      7      2      2      1  sci\n",
       "7      8     12      8     11  his\n",
       "8      9      7      3      5  his\n",
       "9     10      6      5      8  his"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute the most likely class for $x=(5,4,3)$ using the $k$-nearest neighbor classifier with $k=3$ and show how you arrived at your solution.\n",
    "Use the Euclidean distance function and majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  1  1]\n",
      " [13  0  1]\n",
      " [ 8  2  1]\n",
      " [ 7  2  3]\n",
      " [ 2  1  0]\n",
      " [ 1  0  1]\n",
      " [ 2  2  1]\n",
      " [12  8 11]\n",
      " [ 7  3  5]\n",
      " [ 6  5  8]]\n",
      "['spo' 'spo' 'spo' 'spo' 'sci' 'sci' 'sci' 'his' 'his' 'his']\n",
      "spo\n",
      "prediction: ['spo']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "X = df.iloc[:,1:4].values\n",
    "y = df.iloc[:,4].values\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y) \n",
    "\n",
    "print(\"prediction:\", neigh.predict([[5,4,3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Reduce the data set to the mean vectors of each class only.\n",
    "Compute the most likely class for $x$ using the nearest-neighbor classifier on this reduced data set\n",
    "and show how you arrived at your solution. Use the Euclidean distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: ['sci']\n"
     ]
    }
   ],
   "source": [
    "#print(X[0:3])\n",
    "#print(np.mean(X[0:3], axis=0))\n",
    "newX = np.array([np.mean(X[0:3], axis=0), np.mean(X[4:6], axis=0), np.mean(X[7:9], axis=0)])\n",
    "newy = np.array([\"spo\", \"sci\", \"his\"])\n",
    "\n",
    "#print(newX)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(newX, newy) \n",
    "\n",
    "print(\"prediction:\", neigh.predict([[5,4,3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly discuss why the results of the $k$-nearest neighbor classifier could be different from\n",
    "the results obtained by using the nearest-mean classifier from the previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim k-nearest neighbor ist der Testpunkt am nächsten zu zwei Punkten der Klasse \"spo\". Bei nearest-mean am nächsten zum Mittelwert von \"sci\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Tic-Tac-Toe\n",
    "\n",
    "In this exercise we will train a probabilistic model to play Tic-Tac-Toe with us. To do so, download the UCI Tic-Tac-Toe dataset (https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data and make yourself familiar with the data representation. Write code to display a field in your shell using ASCII characters. Write a function `chose_cell` that given the data and using Bayes' Theorem, returns the best cell (as number from 0 to 8) for the first turn of player $X$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "b b b\n",
      "b x b\n",
      "b b b\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tic-tac-toe.data')\n",
    "\n",
    "def display_field(field):\n",
    "    # TODO\n",
    "    for i in [0,3,6]:\n",
    "        print(field[i],field[i+1],field[i+2])\n",
    "    \n",
    "\n",
    "def chose_cell(df):\n",
    "    # TODO\n",
    "    xPositive=np.zeros(9)\n",
    "    count_p=0\n",
    "    X = np.array(df.iloc[:,:-1].values)\n",
    "    Y = np.array(df.iloc[:,-1:].values)\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == \"positive\":\n",
    "            count_p += 1\n",
    "            for j in range(len(X[0])):\n",
    "                if X[i][j] == 'x':\n",
    "                    xPositive[j] += 1\n",
    "    xPositive=[x/count_p for x in xPositive]\n",
    "    return(xPositive.index(max(xPositive)))\n",
    "\n",
    "print(chose_cell(df))\n",
    "test_field = ['b' for i in range(9)]\n",
    "test_field[chose_cell(df)] = 'x'\n",
    "display_field(test_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Adapt your function `chose_cell` to also take the current board situation into consideration and returns the best *blank* cell (as number from 0 to 8) for any turn of player $X$. Use the interactive shell to play against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chose_cell(field,df):\n",
    "    # TODO\n",
    "    xPositive=np.zeros(9)\n",
    "    xPositiveRet=[]\n",
    "    count_p=0\n",
    "    X = np.array(df.iloc[:,:-1].values)\n",
    "    Y = np.array(df.iloc[:,-1:].values)\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == \"positive\":\n",
    "            count_p += 1\n",
    "            for j in range(len(X[0])):\n",
    "                if X[i][j] == 'x':\n",
    "                    xPositive[j] += 1\n",
    "    xPositive=[x/count_p for x in xPositive]\n",
    "    ret=-1\n",
    "    while ret == -1:\n",
    "        if field[xPositive.index(max(xPositive))] != 'b':\n",
    "            xPositive[xPositive.index(max(xPositive))] = 0\n",
    "        else:\n",
    "            return(xPositive.index(max(xPositive)))\n",
    "    return(xPositive.index(max(xPositiveRet)))\n",
    "\n",
    "# Game functions\n",
    "game_field = []\n",
    "def init_game_field():\n",
    "    global game_field # Uses global variables instead of local\n",
    "    game_field = ['b' for i in range(9)]\n",
    "    make_ai_turn()\n",
    "\n",
    "def make_ai_turn():\n",
    "    global df, game_field\n",
    "    # TODO\n",
    "    game_field[chose_cell(game_field,df)] = 'x'\n",
    "    display_field(game_field)\n",
    "\n",
    "def make_human_turn(position):\n",
    "    global game_field\n",
    "    # TODO\n",
    "    game_field[position] = 'o'\n",
    "    display_field(game_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b b b\n",
      "b x b\n",
      "b b b\n",
      "welches Feld?4\n",
      "welches Feld?-1\n"
     ]
    }
   ],
   "source": [
    "# Play here!\n",
    "init_game_field()\n",
    "while 'b' in game_field:\n",
    "    pos = int(input(\"welches Feld?\"))\n",
    "    while game_field[pos] != 'b' and pos != -1:\n",
    "        pos = int(input(\"welches Feld?\"))\n",
    "    if pos == -1:\n",
    "        break\n",
    "    make_human_turn(pos)\n",
    "    make_ai_turn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Create a function `chose_cell_lookahead` that returns the best *blank* cell, for which winning probabilities of player $X$ are best after the player $O$'s turn using Bayes' Theorem. Do you expect to obtain different results? Test your theories by playing against both functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chose_cell_lookahead(field,df):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Count imputation\n",
    "\n",
    "In this exercise we want to use the K Nearest-Neighbor algorithm for traffic prediction. In moodle you can find the file `luxembourg_counts.csv` which contains simulated data from the city of Luxembourg. Our task is to predict the average number of vehicles (counts) in a given region from the morning hours 7:00 to 11:00. To tackle this problem, Luxembourg has been split into multiple grid cells. Each row in `luxembourg_counts.csv` represents one grid cell (identified by its latitude and logitude coordinates) followed by its average vehicle count in the given time slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the data and plot a histogram of traffic counts. Compute a $20\\%$ test split, which will be used to judge the algorithms afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.381795996053057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('luxembourg_counts.csv')\n",
    "\n",
    "# TODO\n",
    "\n",
    "X = df.iloc[:,1:-1].values\n",
    "Y = df.iloc[:,-1].values\n",
    "\n",
    "print(np.mean(df.iloc[:,-1].values))\n",
    "plt.hist(df.iloc[:,-1].values,bins=100)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ausgleich = 0\n",
    "if 0.8*len(df)%1 != 0:\n",
    "    ausgleich = 1\n",
    "split_true = np.ones(int(0.8*len(df))+ausgleich)\n",
    "split_false = np.zeros(int(0.2*len(df)))\n",
    "mask = split_true\n",
    "mask = np.append(mask,split_false)\n",
    "np.random.shuffle(mask)\n",
    "\n",
    "XTrain = X[mask == True]\n",
    "XTest = X[mask == False]\n",
    "YTrain = X[mask == True]\n",
    "YTest = X[mask == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Implement the Mean-Squared-Error function:\n",
    "$$\n",
    "MSE = \\frac{1}{N_{Test}} \\sum_{(x,y)\\in D_{Test}} (f(x) - y)^2\n",
    "$$\n",
    "and a simple baseline model, which always predicts the mean\n",
    "$$\n",
    "f_{base}(x) = \\frac{1}{N_{Train}} \\sum_{(x,y)\\in D_{Train}} y\n",
    "$$\n",
    "Test its performance with a $10-$fold cross validation and the test set. \n",
    "\n",
    "*Note: The jupyter notebook file already contains the necessary template to integrate your own classifier into `sklearn`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class BaselineModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        #We do not have any parameters\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        # Store the classes seen during fit. Since we will do regression, this is not necessary\n",
    "        # self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        # The actual classifier's fit method\n",
    "        # TODO\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # actual predict method\n",
    "        # TODO\n",
    "        \n",
    "        return 0 # return prediction here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def mse(Y,YPredicted):\n",
    "    # TODO\n",
    "\n",
    "\n",
    "my_scorer = make_scorer(mse)\n",
    "\n",
    "xvalScores = []\n",
    "\n",
    "meanModel = BaselineModel();\n",
    "scores = cross_val_score(meanModel, XTrain, YTrain, cv = 10, scoring=my_scorer) \n",
    "score = np.mean(scores)\n",
    "\n",
    "meanModel = BaselineModel();\n",
    "meanModel.fit(XTrain,YTrain)\n",
    "print(\"MSE training = \", score)    \n",
    "print(\"MSE test = \", mse(YTest, meanModel.predict(XTest)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Traffic counts have a large variance, which makes the results difficult to interpret. The Standardized Mean Squared Error\n",
    "$$\n",
    "SMSE = \\frac{1}{N_{Test}\\cdot var( D_{Test})} \\sum_{(x,y)\\in D_{Test}} (f(x) - y)^2\n",
    "$$\n",
    "standardized the MSE by also taking into account the variance $var( D_{Test})$ of the lables in the test data. Implement the SMSE and use it to rate the baseline model. What happens and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def smse(Y,YPred):\n",
    "    # TODO\n",
    "\n",
    "my_scorer = make_scorer(smse)\n",
    "\n",
    "xvalScores = []\n",
    "\n",
    "meanModel = BaselineModel();\n",
    "scores = cross_val_score(meanModel, XTrain, YTrain, cv = 10, scoring=my_scorer) \n",
    "score = np.mean(scores)\n",
    "\n",
    "meanModel = BaselineModel();\n",
    "meanModel.fit(XTrain,YTrain)\n",
    "print(\"MSE training = \", score)    \n",
    "print(\"MSE test = \", mse(YTest, meanModel.predict(XTest)))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement the K-Nearest-Neigbour algorithm and try different $K\\in\\{1,\\dots,20\\}$. What is the best configuration and what is its performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class MyKNN(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        # Store the classes seen during fit. Since we will do regression, this is not necessary\n",
    "        #self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        # The actual classifier's fit method\n",
    "        # TODO\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        # actual predict method\n",
    "        # TODO\n",
    "        return 0 # return prediction here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validating on parameters and chosing best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

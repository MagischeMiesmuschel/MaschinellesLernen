{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a data set $X$, $|X|=2M$, with \\emph{uniform random} labels (independent of the attribute values).\n",
    "Assume that there are no duplicates in $X$. \n",
    "Labels are disjoint, every object is either labeled $C_1$ or $C_2$, and let $|C_1|=|C_2|=M$.\n",
    "\n",
    "Because the labels are random, the `majority` classifier that always\n",
    "predicts the *most frequent label* is the theoretically optimal classifier\n",
    "(as the attributes are not informative, we do not need to use them).\n",
    "\n",
    "Hint: do *not* assume the classifier is *always* trained with $|C_{1,\\text{training}}|=|C_{2,\\text{training}}|$,\n",
    "but make sure to first identify the training set used in this subproblem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the exact error rate of the ``majority'' classifier on the entire data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) If we do leave-one-out validation, what is the estimated error rate using the `majority` classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) If we do .632 bootstrap, what apears to be the best classifier in training, and what is its estimated error rate?\n",
    "(Note: this is the difficult part of the assignment. Use just one iteration, $k=1$, for simplicity.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Interpret these results with respect to the \\emph{evaluation procedure}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2-2\n",
    "\n",
    "In Moodle, you can find the data set `sonar.all-data`, which contains sonar measurements from a mine-sweeper ship. Each line in the files contains 60 sensor measurements, all separated by a comma followed by the class label in the last column (`M`: mine, `R`: rock).\n",
    "\n",
    "You are encouraged to use `numpy` functionality where appropriate, but you may not use `sklearn`\n",
    "functionality (such as the existing evaluation functions) except for the classifiers given in the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sonar.all-data', header=None)\n",
    "\n",
    "# Return a (sampled) fraction of all samples. Since frac=1, this is the whole data-set but shuffled\n",
    "# In addition we reset the index (line numbers)\n",
    "df = df.sample(frac=1).reset_index(drop=True) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Randomly split the data set into two disjunct subsets (`XTrain`, `YTrain`) and \n",
    "(`XTest`, `YTest`), where the training data contains $80 \\%$ of the original data. \n",
    "Print the shape of each array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Implement a function `accuracy(classifier,X1,y1,X2,y2)` that uses the function `classifier.fit` to train on $(X_1,y_1)$, then `classifier.predict` to predict labels for $X_2$, and then returns the accuracy of this prediction.\n",
    "\n",
    "Assume that the classifier uses the following API:\n",
    "\n",
    "`classifier.fit(X,y)`: Trains the classifier on training matrix $X \\in \\mathbb R^{n\\times d}$ with label vector $y \\in \\mathbb R^n$. Returns the trained model.\n",
    "\n",
    "`classifier.predict(X)`: Applies the previously trained classifier on test data $X \\in \\mathbb R^{n\\times d}$. Returns a vector of predictions $\\widehat y \\in \\mathbb R^{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(classifier,X1,y1,X2,y2):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implement a function `holdout_evaluation(X,y,p,k,measure,classifier)`\n",
    "that selects rows with probability $p$ into the training data $(X_1,y_1)$,\n",
    "and uses the remaining data as validation data $(X_2,y_2)$.\n",
    "\n",
    "Make sure that the labels correspond to the data rows.\n",
    "The function then calls the function `measure` for the given `classifier`, and the generated training and validation data.\n",
    "Return the average and standard deviation of $k$ repetitions of this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_evaluation(X,y,k,p,measure,classifier):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement a function `cross_validation(X,y,k,measure,classifier)` that `randomly` partitions the data into $k$ disjoint partitions, whose sizes differ by at most 1.\n",
    "\n",
    "Return the average score (and standard deviation) measured by `measure` using the given `classifier`,\n",
    "when using each partition `once` for testing, and all `other` partitions for training (i.e., $k$ runs total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X,y,k,measure,classifier):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Run the provided code to compare different classifiers. \n",
    "Discuss the result: which classifier(s) would you pick based on each of the validation procedures,\n",
    "and what accuracy do you predict for future data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define various classifiers that we want to benchmark.\n",
    "import numpy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifiers = [\n",
    "    (\"KNN k=1\", KNeighborsClassifier(1)), (\"KNN k=2\", KNeighborsClassifier(2)),\n",
    "    (\"KNN k=5\", KNeighborsClassifier(5)), (\"KNN k=10\", KNeighborsClassifier(10)),\n",
    "    (\"DecTree maxDepth=2\", DecisionTreeClassifier(max_depth=2)),\n",
    "    (\"DecTree maxDepth=4\", DecisionTreeClassifier(max_depth=4)),\n",
    "    (\"DecTree maxDepth=6\", DecisionTreeClassifier(max_depth=6))\n",
    "]\n",
    "\n",
    "# Benchmark classifiers.\n",
    "print(\"Classifier\\t\\tHoldout Eval.\\tCross-Val.\\tTrain\\tTest\")\n",
    "for name, classifier in classifiers:\n",
    "    numpy.random.seed(0)\n",
    "    ho, hos = holdout_evaluation(XTrain, YTrain, 10, 1./3, accuracy, classifier)\n",
    "    cv, cvs = cross_validation(XTrain, YTrain, 10, accuracy, classifier)\n",
    "    tr = accuracy(classifier, XTrain, YTrain, XTrain, YTrain)\n",
    "    te = accuracy(classifier, XTrain, YTrain, XTest, YTest)\n",
    "    print(\"%-20s\\t%.3f ± %.3f\\t%.3f ± %.3f\\t%.3f\\t%.3f\" % (name, ho, hos, cv, cvs, tr, te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

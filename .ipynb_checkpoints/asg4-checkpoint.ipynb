{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "\n",
    "Prove that the following two equations for computing the entropy of a set $T$ (with respect to classes\n",
    "$C_1,\\ldots,C_k$) are equivalent:\n",
    "\n",
    "$$\\text{entropy}(T)=-\\sum_{i=1}^k p_i \\cdot \\log(p_i)$$\n",
    "\n",
    "$$\\text{entropy}(T)=-\\frac{1}{|T|} \\left( \\sum_{i=1}^k c_i \\cdot \\log(c_i) \\right) + \\log(|T|)$$\n",
    "\n",
    "where $c_i = \\vert C_i \\cap T \\vert$ denotes the number of object in $T$ that are in class $C_i$ and $p_i$ denotes the probability of an object in $T$ to be within $C_i$.\n",
    "\n",
    "You can assume the $C_i$ to be disjoint and that every object in $T$ is contained in exactly one $C_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [ 23 , 'm', 'low'],\n",
    "    [ 35 , 'f', 'low'],\n",
    "    [ 25 , 'm', 'low'],\n",
    "    [ 78 , 'f', 'low'],\n",
    "    [ 46 , 'f', 'med'],\n",
    "    [ 81 , 'f', 'med'],\n",
    "    [ 47 , 'm', 'med'],\n",
    "    [ 55 , 'm', 'high'],\n",
    "    [ 71 , 'f', 'high'],\n",
    "    [ 41 , 'm', 'high']],\n",
    "    columns=[  \"Age\", \"Gender\", \"Cancer-Risk\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following data set of patient records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Cancer-Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>m</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>f</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>m</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>f</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81</td>\n",
       "      <td>f</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "      <td>m</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>m</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71</td>\n",
       "      <td>f</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>m</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Cancer-Risk\n",
       "0   23      m         low\n",
       "1   35      f         low\n",
       "2   25      m         low\n",
       "3   78      f         low\n",
       "4   46      f         med\n",
       "5   81      f         med\n",
       "6   47      m         med\n",
       "7   55      m        high\n",
       "8   71      f        high\n",
       "9   41      m        high"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Discretize the Age attribute into the values $\\{< 40, [40:70], > 70 \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code or write a Markdown block containing your computations and results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) For the discretized age attribute only, compute for $T$ and for each partition $T_i$ the (1) entropy and (2) gini index.\n",
    "Then compute the resulting (3) information gain and (4) $\\operatorname{Benefit}_{\\operatorname{Gini}}$ of the split\n",
    "with respect to their ability to predict Cancer-Risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You do not need to do this as code.\n",
    "# Preferably, make this by hand and write a Markdown block.\n",
    "# In that case, you can delete the code frame below.\n",
    "\n",
    "def entropy(T):\n",
    "    # TODO\n",
    "\n",
    "def gini(T):\n",
    "    # TODO\n",
    "\n",
    "def information_gain(T, column):\n",
    "    # TODO: column is the splitting attribute\n",
    "\n",
    "def benefit(T, column):\n",
    "    # TODO: column is the splitting attribute\n",
    "\n",
    "# TODO: Output results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Construct the decision tree of the above records and attributes using the Gini index split strategy only.\n",
    "Stop if all remaining attributes are constant. Argue how you choose the prediction of a leaf.\n",
    "\n",
    "Draw the tree with all necessary information to predict new records.\n",
    "\n",
    "Hint: You do not need to compute the benefit, if you have only one candidate attribute remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You do not need to do this as code.\n",
    "# Preferably, make this by hand and write a Markdown block.\n",
    "# For printing your results (using either way), you can use the class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self,parent=None,classification=None,attr_val=None,column=None):\n",
    "        self.classification = classification\n",
    "        self.attr_val = attr_val\n",
    "        self.column = column\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "        if not parent is None:\n",
    "            parent.add_child(self)\n",
    "    \n",
    "    def children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def add_child(self,tree):\n",
    "        self.children.append(tree)\n",
    "        tree.parent = self\n",
    "    \n",
    "    def depth_in_tree(self):\n",
    "        if self.parent is None:\n",
    "            return 0\n",
    "        return 1+self.parent.depth_in_tree()\n",
    "    \n",
    "    def print_self(self,column_names):\n",
    "        self._print_self_helper(\"\",column_names)\n",
    "        \n",
    "    def _print_self_helper(self,prefix,column_names):\n",
    "        if len(self.children) > 0:\n",
    "            print(prefix,\"(\"+str(self.attr_val)+\")\",column_names[self.column])\n",
    "            for child in self.children:\n",
    "                child._print_self_helper(\" |  \"*(len(prefix)//4)+\" |--\",column_names)\n",
    "        else:\n",
    "            print(prefix,\"(\"+str(self.attr_val)+\")\",self.classification)\n",
    "\n",
    "# Usage:\n",
    "# Create a root node with Tree()\n",
    "# Create any further node with Tree(parent=<parent node>) or with Tree() and later call parent.add_child(child)\n",
    "# Use the classification attribute in leaved for the classification value\n",
    "# Use the column attribute in inner nodes to specify the splitting attribute\n",
    "# Use the attr_val attribute in all nodes to specify the attribute value of the previous split\n",
    "# All attributes can be changed at any time\n",
    "# Print the entire tree with <root>.print_self()\n",
    "\n",
    "# Example:\n",
    "# Creates a DT with random splits up to a maximum depth.\n",
    "# Classification labels are chosen arbitrary and do not represent real classifications.\n",
    "import numpy as np\n",
    "def print_example_DT(df):\n",
    "    n_attrs = len(df.columns)-1\n",
    "    first_split = np.random.randint(n_attrs)\n",
    "    second_split = (first_split + np.random.randint(n_attrs-2) + 1) % n_attrs\n",
    "    classes = list(set(df[df.columns[-1]]))\n",
    "    attr_vals = [list(set(df[df.columns[i]])) for i in range(len(df.columns)-1)]\n",
    "    # First split with attribute first_split\n",
    "    root = Tree(column=first_split)\n",
    "    for val in attr_vals[first_split]:\n",
    "        # Second split with attribute second_split\n",
    "        inner_node = Tree(parent=root,column=second_split,attr_val=val)\n",
    "        for val2 in attr_vals[second_split]:\n",
    "            c = classes[np.random.randint(len(classes))]\n",
    "            leaf = Tree(\n",
    "                parent=inner_node,\n",
    "                classification=c,\n",
    "                attr_val=val2)\n",
    "    root.print_self(df.columns)\n",
    "\n",
    "print_example_DT(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Predict the class labels of the new records given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf = pd.DataFrame([\n",
    "    [ 35 , 'm', None ],\n",
    "    [ 28 , 'f', None ],\n",
    "    [ 48 , 'm', None ],\n",
    "    [ 55 , 'f', None ],\n",
    "    [ 83 , 'm', None ],\n",
    "    [ 72 , 'f', None ]],\n",
    "    columns=[  \"Age\", \"Gender\", \"Cancer-Risk\" ])\n",
    "qdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute in a Markdown block and write results into the Dataframe qdf.\n",
    "# You may code it, but that's quite advanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mushroom Classification\n",
    "\n",
    "We use a variant of the well known Mushroom data from the UCI machine learning repository.\n",
    "\n",
    "Use the `mushroom.csv` found on the Moodle website. In this jupyter template file you can find some code snippets to load the data and do intermediate processing. Please implement missing functions flagged with `#TODO`\n",
    "\n",
    "*Note:* In the lecture we discussed DTs for categorical inputs. `SKLearn`'s DTs are implemented using numerical attributes which makes it difficult to use the `SKLearn`'s interface directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "df = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "column_names = df.columns\n",
    "X = df.to_numpy()[:,:-1]\n",
    "y = df.to_numpy()[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implement a function `gini(y)` to compute the Gini for labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Implement a function `entropy(y)` to compute the information entropy for labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implement a function `classification_error(y)` to compute the classification error for labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y):\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement `gain_ratio` quality function for labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(attribute, y):\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the provided benefit function to transform an impurity measure into a benefit measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benefit(X, y, impurity):\n",
    "    score = impurity(y)\n",
    "    for v in numpy.unique(X):\n",
    "        subset = y[X == v]\n",
    "        score = score - len(subset)/float(len(y)) * impurity(subset)\n",
    "    return score\n",
    "\n",
    "gini_benefit = lambda X,y: benefit(X,y,gini)\n",
    "information_gain = lambda X,y: benefit(X,y,entropy)\n",
    "error_benefit = lambda X,y: benefit(X,y,classification_error)\n",
    "print(column_names[0], gini_benefit(X[:,0], y), information_gain(X[:,0], y), error_benefit(X[:,0], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Implement a function `find_best(X, y, quality)` to find the best attribute in $X$, using\n",
    "the given quality function (e.g., `gini_benefit`). The function must return the quality\n",
    "as well as the best attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(X, y, quality):\n",
    "    # TODO\n",
    "    return column, quality_value\n",
    "\n",
    "print(find_best(X, y, gini_benefit),     column_names[find_best(X, y, gini_benefit)[1]])\n",
    "print(find_best(X, y, information_gain), column_names[find_best(X, y, information_gain)[1]])\n",
    "print(find_best(X, y, error_benefit),    column_names[find_best(X, y, error_benefit)[1]])\n",
    "print(find_best(X, y, gain_ratio),       column_names[find_best(X, y, gain_ratio)[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Implement a recursive function `split(X,y,quality)` to construct a decision tree.<br/>\n",
    "Stop when a branch is pure, and always split into all distinct attribute values of the *best* attribute.<br/>\n",
    "If more than one attribute has the same score, use the *first* of the best attributes.\n",
    "\n",
    "Return the result as a an object of the `Tree` class provided in *Decision Trees c)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, quality):\n",
    "    root = Tree()\n",
    "    # TODO\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Use the provided `print_self` method of the `Tree` class to print the different trees using the quality measures `gini_benefit`, `information_gain`, `error_benefit` and `gain_ratio`.\n",
    "\n",
    "What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gini:\")\n",
    "tree = split(X, y, gini_benefit)\n",
    "tree.print_self(df.columns)\n",
    "print(\"\\nInformation Gain:\")\n",
    "# TODO\n",
    "print(\"\\nClassification Error:\")\n",
    "# TODO\n",
    "print(\"\\nGain ratio:\")\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Write what you notice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

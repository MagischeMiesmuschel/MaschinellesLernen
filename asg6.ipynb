{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Trick\n",
    "\n",
    "In this exercise you learn to work with kernel functions directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the feature map $\\phi$ of the polynomial kernel $K(\\vec x, \\vec y) = (\\vec x^T \\vec y)^d$ for two-dimensional ($d = 2$) observations $\\vec x, \\vec y \\in \\mathbb R^d$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Consider the radial basis function kernel (RBF) / Gaussian Kernel:\n",
    "$$ K(\\vec x, \\vec y) = \\exp \\left(-\\frac{1}{2}||\\vec x - \\vec y||^2\\right) $$\n",
    "It is possible to show, that the feature map of this kernel is given by:\n",
    "$$ \\phi(\\vec x)^T \\phi(\\vec y) = \\sum_{j=0}^\\infty \\frac{(\\vec x^T \\vec y)^j}{j!}\\exp\\left(-\\frac{1}{2}||\\vec x||\\right)\\exp\\left(-\\frac{1}{2}||\\vec y||\\right) $$\n",
    "Evaluate this kernel:\n",
    " - What dimensionality has its feature map?\n",
    " - What does this mean for the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines with SKLearn\n",
    "\n",
    "In this task we will explore the decision boundaries for two classes with $d = 2$ for the SVM. To do so, we will use the `make_blob` function from `SKLearn`. In the jupyter notebook you can find an example using `make_blobs` to generate some data. Furthermore, you can find a simple function `plot_svc_decision_function` which plots the support vectors and decision boundaries of a trained SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from plotly import graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Example\n",
    "blobs = make_blobs(n_samples=400,n_features=2,centers=2,cluster_std=2,random_state=42)\n",
    "X = blobs[0]\n",
    "y = blobs[1]\n",
    "\n",
    "X0 = X[y==0]\n",
    "X1 = X[y==1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X0[:,0],y=X0[:,1],mode=\"markers\",fillcolor=\"red\"))\n",
    "fig.add_trace(go.Scatter(x=X1[:,0],y=X1[:,1],mode=\"markers\",fillcolor=\"blue\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, xlim=None, ylim=None, plot_support=False):\n",
    "    # If provided a function, this will fail and set is_fun to True\n",
    "    is_fun = False\n",
    "    try:\n",
    "        dump = model.decision_function([[0,0]])\n",
    "    except:\n",
    "        is_fun = True\n",
    "    if xlim is None:\n",
    "        xlim = [0,1]\n",
    "    if ylim is None:\n",
    "        ylim = [0,1]\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    if is_fun:\n",
    "        P = np.array([model(p) for p in xy]).reshape(X.shape)\n",
    "    else:\n",
    "        P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    fig = go.Figure(layout=go.Layout(\n",
    "        xaxis=dict(range=xlim),\n",
    "        yaxis=dict(range=ylim)\n",
    "    ))\n",
    "    fig.add_trace(go.Contour(x=x,y=y,z=P.T,contours=dict(start=-1,end=1,size=1)))\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support and not is_fun:\n",
    "        pos_supp = model.support_vectors_[model.dual_coef_[0] >= 0]\n",
    "        neg_supp = model.support_vectors_[model.dual_coef_[0] < 0]\n",
    "        fig.add_trace(go.Scatter(x=pos_supp[:,0],y=pos_supp[:, 1], mode=\"markers\", fillcolor=\"red\"))\n",
    "        fig.add_trace(go.Scatter(x=neg_supp[:,0],y=neg_supp[:, 1], mode=\"markers\", fillcolor=\"cyan\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Use the `make_blobs` function to generate two datasets with $N=60$ and $N=120$ data points with $2$ centers and `cluster_std` equal to $0.6$. Make sure to use the same `random_state` (seed) for both data sets.\n",
    "\n",
    "Train a linear SVM model with $C = 1e10$ on both data sets and plot the decision boundaries using `plot_svc_decision_function` function.\n",
    "\n",
    "Compare both decision boundaries - What do you see? Interpret the results with respect to the optimization problem of the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC # <- This is the linear SVM model of sklearn\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the `make_blobs` function to generate a dataset with $N=100$ data points with $2$ centers and a `cluster_std` of $0.8$.\n",
    "\n",
    "Train two linear SVM models on this data set:\n",
    " - For the first SVM use $C = 10$.\n",
    " - For the second one, use $C = 0.1$.\n",
    " \n",
    "Again, plot the decision boundaries using `plot_svc_decision_function` function.\n",
    "\n",
    "Compare both decision boundaries - What do you see? Interpret the results with respect to the optimization problem of the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Implement a grid search to find the best SVM with respect to its cross-validated accuracy on the `iris` data set. Use a $5$-fold cross validation and vary different $C$ parameters, as well as kernels and their parameters. You may use SKLearns' `GridSearchCV` function to implement the grid search. A list of kernels can be found here https://scikit-learn.org/stable/modules/svm.html#svm-kernels.\n",
    "\n",
    "What is the best configuration you can find and what is its accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Logic Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Design a TLU Network for each of the following Boolean functions:\n",
    "\n",
    " - $f(x) = x_1 \\neg x_2 \\neg x_3 \\lor \\neg x_1 x_3 \\lor x_1 x_4$\n",
    " - $g(x) = (x_1 \\lor x_2) \\land (\\neg x_3 \\lor x_2x_3) \\land (x_4 x_5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) How many computations (summation and multiplication) are necessary to compute the output of the following networks? How many parameters are stored in each network?\n",
    "\n",
    "*Note:* Here $10 \\to 20$ denotes a layer with $10$ inputs and $20$ outputs.\n",
    "\n",
    " - $N_1: 10 \\to 20 \\to 10$\n",
    " - $N_2: 10 \\to 200 \\to 10 \\to 10$\n",
    " - $N_3: 10 \\to 200 \\to 500 \\to 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Design a TLU structure with only two units which implements XOR.\n",
    "\n",
    "*Hint:* Your design does not need to be a layered network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs and Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Consider a linear SVM with provided $\\vec{w} = (-1,2)$ and $b = -3$.\n",
    "\n",
    "Draw a minimal perceptron network, that encodes the linear SVM classifier with a minimal number of perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) You are using an SVM with the $\\tanh$ kernel function $k(x,y) = \\tanh(\\alpha x^Ty + c)$ on data in $\\mathbb{R}^3$. After training, you obtain the all primal and dual parameters for the kernel SVM and wish to encode the classifier in a perceptron network.\n",
    "\n",
    "How many perceptrons are necessary to encode the parametrized classifier?\n",
    "\n",
    "*Hint:* Take a look at the dual classification function on slide $2:93$ of the lecture. You will have to replace the product with the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) In the jupyter notebook, you are provided with a dataset and a fitted kernel SVM classifier. You can obtain the parameters of the kernel SVM via the fields `support_vectors_` $(x_i)$ and `dual_coef_` $(\\lambda_i y_i)$. The parameter $\\alpha$ is $0.25$ and $c$ is $-2$. Compute the matrices necessary to compute classifications analogous to the formula from the lecture:\n",
    "\n",
    "$$ f(\\vec{x}) = \\varphi_2(W_2 \\cdot \\mathbb{1} \\varphi_1(W_1 \\cdot \\mathbb{1} \\vec{x})$$\n",
    "\n",
    "Write a function `perceptron_SVM`, that returns $-1$ or $1$ for a given point and test your perceptron network against the provided SVM with the `same_decision` function provided in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "moons = make_moons(1000,noise=.1,random_state=42)\n",
    "X = moons[0]\n",
    "y = moons[1]*2-1\n",
    "svc = SVC(C=100,kernel='sigmoid', gamma=.25, coef0=-2)\n",
    "svc.fit(X,y)\n",
    "\n",
    "# Show decision boundaries\n",
    "plot_svc_decision_function(svc, xlim=[-1.5,2.5], ylim=[-1,1.5])\n",
    "\n",
    "# Show raw data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X[y==-1][:,0],y=X[y==-1][:,1], mode=\"markers\",fillcolor=\"red\"))\n",
    "fig.add_trace(go.Scatter(x=X[y==1][:,0],y=X[y==1][:,1], mode=\"markers\",fillcolor=\"blue\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = .25\n",
    "c = -2\n",
    "\n",
    "# Adds as many 1's as necessary to stretch p to length l\n",
    "# Example: padded([5,4,6],6) = [1,1,1,5,4,6]\n",
    "def padded(p, l):\n",
    "    ret = np.ones(l)\n",
    "    ret[-len(p):] = p\n",
    "    return ret\n",
    "\n",
    "M1 = None # TODO\n",
    "M2 = None # TODO\n",
    "\n",
    "def perceptron_svc(p):\n",
    "    global M1, M2\n",
    "    # TODO\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def same_decision(func):\n",
    "    global svc\n",
    "    N = 2000\n",
    "    l = []\n",
    "    for p in np.random.sample(N).reshape(N//2,2)*4-1.5:\n",
    "        l.append([*p,func(p)])\n",
    "        if svc.predict([p])[0] != func(p):\n",
    "            print(\"Prediction did not match on point ({:6.4f}, {:6.4f}).\".format(p[0],p[1]))\n",
    "            return False\n",
    "    l = np.array(l)\n",
    "    fig = go.Figure()\n",
    "    la = l[l[:,2]>0][:,:2].T\n",
    "    lb = l[l[:,2]<0][:,:2].T\n",
    "    fig.add_trace(go.Scatter(x=la[0],y=la[1],mode=\"markers\"))\n",
    "    fig.add_trace(go.Scatter(x=lb[0],y=lb[1],mode=\"markers\"))\n",
    "    fig.show()\n",
    "    print(\"All predictions were the same as the kernel SVM.\")\n",
    "    return True\n",
    "\n",
    "same_decision(perceptron_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
